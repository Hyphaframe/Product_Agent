

"""
Streamlit Webç•Œé¢ - LangGraphç‰ˆæœ¬
è‡ªåŠ¨è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥ï¼Œæä¾›å‹å¥½çš„Webç•Œé¢è¿›è¡Œæ·±åº¦æœç´¢ï¼›
æ”¯æŒå®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œç»“æœåˆ†æ ‡ç­¾é¡µå±•ç¤ºã€‚
"""
import os
import sys

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), ".")))

import streamlit as st
from src import DeepSearchAgent, Config
from src.utils.config import load_config


def main():
    # -------------------- é¡µé¢é…ç½® --------------------
    st.set_page_config(
        page_title="Deep Search Agent (LangGraphç‰ˆæœ¬)",
        page_icon="ğŸ”",
        layout="wide",
    )

    st.title("ğŸ” Deep Search Agent (LangGraphç‰ˆæœ¬)")
    st.markdown("åŸºäºLangGraphçš„æ·±åº¦æœç´¢AIä»£ç† - è‡ªåŠ¨è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥")

    # -------------------- ä¾§è¾¹æ é…ç½® --------------------
    try:
        default_config = load_config()
        has_config_file = True
        st.sidebar.success("âœ… å·²æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶ï¼ŒAPI Key å·²è‡ªåŠ¨å¡«å……")
    except Exception:
        default_config = None
        has_config_file = False
        st.sidebar.warning("âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥APIå¯†é’¥")

    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")

        # --- API å¯†é’¥ ---
        st.subheader("APIå¯†é’¥")
        openai_api_key = st.text_input(
            "OpenAI/ç¡…åŸºæµåŠ¨ API Key",
            value=default_config.openai_api_key if has_config_file else "",
            type="password",
            help="ä»é…ç½®æ–‡ä»¶è‡ªåŠ¨è¯»å–ï¼Œæˆ–æ‰‹åŠ¨è¾“å…¥",
        )
        openai_model = st.text_input(
            "æ¨¡å‹åç§°",
            value=default_config.openai_model if has_config_file else "deepseek-ai/DeepSeek-V3",
            help="ä¾‹å¦‚ï¼šdeepseek-ai/DeepSeek-V3 (ç¡…åŸºæµåŠ¨) æˆ– gpt-4o-mini (OpenAI)",
        )
        tavily_api_key = st.text_input(
            "Tavily API Key",
            value=default_config.tavily_api_key if has_config_file else "",
            type="password",
            help="ä»é…ç½®æ–‡ä»¶è‡ªåŠ¨è¯»å–ï¼Œæˆ–æ‰‹åŠ¨è¾“å…¥",
        )

        # --- ç ”ç©¶å‚æ•° ---
        st.subheader("ç ”ç©¶å‚æ•°")
        max_reflections = st.slider(
            "åæ€æ¬¡æ•°",
            min_value=0,
            max_value=5,
            value=default_config.max_reflections if has_config_file else 2,
            help="æ¯ä¸ªæ®µè½çš„åæ€æœç´¢æ¬¡æ•°",
        )
        max_search_results = st.slider(
            "æœç´¢ç»“æœæ•°",
            min_value=1,
            max_value=10,
            value=default_config.max_search_results if has_config_file else 3,
            help="æ¯æ¬¡æœç´¢è¿”å›çš„ç»“æœæ•°é‡",
        )
        max_content_length = st.number_input(
            "å†…å®¹æœ€å¤§é•¿åº¦",
            min_value=5000,
            max_value=50000,
            value=default_config.max_content_length if has_config_file else 20000,
            step=5000,
            help="æœç´¢å†…å®¹çš„æœ€å¤§å­—ç¬¦æ•°",
        )
        output_dir = st.text_input(
            "æŠ¥å‘Šä¿å­˜ç›®å½•",
            value=default_config.output_dir if has_config_file else "reports",
            help="æŠ¥å‘Šæ–‡ä»¶çš„ä¿å­˜ä½ç½®",
        )

        st.markdown("---")
        st.markdown("### å…³äº")
        st.markdown(
            """
            è¿™æ˜¯ Deep Search Agent çš„ LangGraph ç‰ˆæœ¬ï¼Œä½¿ç”¨å£°æ˜å¼å›¾ç»“æ„å®ç°ç ”ç©¶å·¥ä½œæµã€‚

            **æ–°ç‰¹æ€§ï¼š**
            - å®æ—¶è¿›åº¦æ˜¾ç¤º
            - å¯è§†åŒ–å·¥ä½œæµé˜¶æ®µ
            - ç»“æœåˆ†æ ‡ç­¾é¡µå±•ç¤º
            - è‡ªåŠ¨è¯»å–é…ç½®æ–‡ä»¶
            """
        )

    # -------------------- ä¸»ç•Œé¢è¾“å…¥ --------------------
    st.header("ğŸ“ ç ”ç©¶æŸ¥è¯¢")
    query = st.text_area(
        "è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜",
        height=100,
        placeholder="ä¾‹å¦‚ï¼š2025å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
        help="è¾“å…¥æ‚¨æƒ³è¦æ·±åº¦ç ”ç©¶çš„é—®é¢˜",
    )

    col1, col2 = st.columns([1, 4])
    with col1:
        start_research = st.button("ğŸš€ å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True)
    with col2:
        save_report = st.checkbox("ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶", value=True)

    # -------------------- ç ”ç©¶æ‰§è¡Œ --------------------
    if start_research:
        # ç®€å•æ ¡éªŒ
        if not tavily_api_key:
            st.error("âŒ è¯·è¾“å…¥ Tavily API Key")
            return
        if not openai_api_key:
            st.error("âŒ è¯·è¾“å…¥ OpenAI/ç¡…åŸºæµåŠ¨ API Key")
            return
        if not query.strip():
            st.error("âŒ è¯·è¾“å…¥ç ”ç©¶é—®é¢˜")
            return

        try:
            # æ„é€ é…ç½®
            config = Config(
                openai_api_key=openai_api_key,
                tavily_api_key=tavily_api_key,
                default_llm_provider="openai",
                openai_model=openai_model,
                max_reflections=max_reflections,
                max_search_results=max_search_results,
                max_content_length=max_content_length,
                output_dir=output_dir,
                save_intermediate_states=False,
            )

            # åˆå§‹åŒ– Agent
            with st.spinner("æ­£åœ¨åˆå§‹åŒ– Deep Search Agent (LangGraphç‰ˆæœ¬)..."):
                agent = DeepSearchAgent(config)
            st.success("âœ… Agent åˆå§‹åŒ–æˆåŠŸ")

            # ---- å®æ—¶è¿›åº¦å±•ç¤º ----
            st.markdown("---")
            st.header("ğŸ”„ ç ”ç©¶è¿›åº¦")

            progress_placeholder = st.empty()
            status_placeholder = st.empty()

            # èŠ‚ç‚¹ä¸­æ–‡æ˜ å°„
            node_names = {
                "structure": "ğŸ“‹ ç”ŸæˆæŠ¥å‘Šç»“æ„",
                "search": "ğŸ” æ‰§è¡Œæœç´¢",
                "summary": "ğŸ“ ç”Ÿæˆæ€»ç»“",
                "reflect": "ğŸ¤” åæ€æœç´¢",
                "reflect_summary": "âœï¸ æ›´æ–°æ€»ç»“",
                "next_paragraph": "â¡ï¸ ç§»åŠ¨åˆ°ä¸‹ä¸€æ®µè½",
                "format": "ğŸ“„ æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š",
            }

            final_report = None
            for progress_data in agent.research(query, save_report=save_report):
                if progress_data["node"] == "completed":
                    final_report = progress_data["report"]
                    status_placeholder.success("âœ… ç ”ç©¶å®Œæˆï¼")
                    break
                else:
                    node = progress_data["node"]
                    state = progress_data["state"]
                    node_display = node_names.get(node, node)
                    status_placeholder.info(f"å½“å‰é˜¶æ®µï¼š{node_display}")

                    # æ®µè½è¿›åº¦æ¡
                    if "current_paragraph_index" in state and "paragraphs" in state:
                        current_idx = state["current_paragraph_index"]
                        total = len(state["paragraphs"])
                        if total > 0:
                            progress_placeholder.progress(
                                (current_idx + 1) / total,
                                text=f"æ®µè½è¿›åº¦ï¼š{current_idx + 1}/{total}",
                            )

            # -------------------- ç»“æœå±•ç¤º --------------------
            if final_report:
                st.markdown("---")
                st.header("ğŸ“Š ç ”ç©¶ç»“æœ")
                tab1, tab2 = st.tabs(["ğŸ“„ æœ€ç»ˆæŠ¥å‘Š", "ğŸ’¾ ä¸‹è½½"])
                with tab1:
                    st.subheader("â±ï¸ è¿è¡Œç»Ÿè®¡")  
                    st.metric("è¿è¡Œæ—¶é—´", f"{progress_data['run_time']:.2f} ç§’")
                    st.markdown(final_report)
                with tab2:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ Markdown æŠ¥å‘Š",
                        data=final_report,
                        file_name=f"deep_search_report_{query[:20]}.md",
                        mime="text/markdown",
                    )

        except Exception as e:
            st.error(f"âŒ ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            st.exception(e)


if __name__ == "__main__":
    main()